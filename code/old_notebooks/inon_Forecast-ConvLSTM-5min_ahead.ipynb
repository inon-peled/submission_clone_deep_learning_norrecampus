{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets, linear_model\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "# prevent tensorflow from allocating the entire GPU memory at once\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "#warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, num_lags, bootstrap_size):\n",
    "    assert bootstrap_size > num_lags\n",
    "    \n",
    "    # read data from file\n",
    "    f = open(filename)\n",
    "    series = []\n",
    "    removed_seasonality = [] \n",
    "    removed_std = []\n",
    "    missings = []\n",
    "    for line in f:\n",
    "        splt = line.split(\",\")\n",
    "        series.append(float(splt[0]))\n",
    "        removed_seasonality.append(float(splt[1]))\n",
    "        removed_std.append(float(splt[2]))\n",
    "        missings.append(int(splt[3]))\n",
    "    series = np.array(series)\n",
    "    removed_seasonality = np.array(removed_seasonality)\n",
    "    removed_std = np.array(removed_std)\n",
    "    missings = np.array(missings)\n",
    "    f.close()\n",
    "\n",
    "    # generate lags\n",
    "    X = []\n",
    "    for i in range(bootstrap_size, len(series)):\n",
    "        X.append(series[i-num_lags:i])\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y = series[bootstrap_size:]\n",
    "    removed_seasonality = removed_seasonality[bootstrap_size:]\n",
    "    removed_std = removed_std[bootstrap_size:]\n",
    "    missings = missings[bootstrap_size:]\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    return X, y, removed_seasonality, removed_std, missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data for place id: s8\n",
      "reading data for place id: _k\n",
      "reading data for place id: QE\n",
      "reading data for place id: 5U\n",
      "reading data for place id: LQ\n",
      "reading data for place id: vU\n",
      "reading data for place id: aM\n",
      "reading data for place id: Gc\n",
      "reading data for place id: kI\n",
      "(9, 51552, 10, 1)\n",
      "(9, 51552)\n",
      "n_instances: 51552\n",
      "n_places: 9\n",
      "n_lags: 10\n"
     ]
    }
   ],
   "source": [
    "# read data from different places\n",
    "NUM_LAGS = 10\n",
    "bootstrap_size = 12*24*1\n",
    "ids = []\n",
    "removed_seasonality_all = []\n",
    "removed_std_all = []\n",
    "missings_all = []\n",
    "X_all = []\n",
    "y_all = []\n",
    "for fname in os.listdir('filipe_places'):\n",
    "    print \"reading data for place id:\", fname[-6:-4]\n",
    "    X, y, removed_seasonality, removed_std, missings = load_data('filipe_places/'+fname, NUM_LAGS, bootstrap_size)\n",
    "    ids.append(fname[-6:-4])\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "    removed_seasonality_all.append(removed_seasonality)\n",
    "    removed_std_all.append(removed_std)\n",
    "    missings_all.append(missings)\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "print X_all.shape\n",
    "print y_all.shape\n",
    "n_places = len(ids)\n",
    "n_instances = X_all.shape[1]\n",
    "print \"n_instances:\", n_instances\n",
    "print \"n_places:\", n_places\n",
    "print \"n_lags:\", NUM_LAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "X = np.swapaxes(X_all, 0, 1)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "X = X[:,:,:,:,np.newaxis]\n",
    "print X.shape\n",
    "y = np.swapaxes(y_all, 0, 1)\n",
    "y = y[:,np.newaxis,:,np.newaxis,np.newaxis]\n",
    "print y.shape\n",
    "\n",
    "STEPS_AHEAD = 1\n",
    "X = X[:,:NUM_LAGS-STEPS_AHEAD+1,:,:]\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 12*24*89\n",
    "n_test = n_train + 12*24*90\n",
    "X_train = X[:n_train,:]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:n_test,:]\n",
    "y_test = y[n_train:n_test]\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(trues, predicted):\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    mse = np.mean((predicted - trues)**2)\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, mse, rae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_filtered(trues, predicted, filt):\n",
    "    trues = trues[filt]\n",
    "    predicted = predicted[filt]\n",
    "    corr = np.corrcoef(predicted, trues)[0,1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    mse = np.mean((predicted - trues)**2)\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return corr, mae, mse, rae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_quantiles(lower, upper, trues, preds):\n",
    "    N = len(trues)\n",
    "    icp = 1.0*np.sum((trues>lower) & (trues<upper)) / N\n",
    "    diffs = np.maximum(0, upper-lower)\n",
    "    mil = np.sum(diffs) / N\n",
    "    rmil = 0.0\n",
    "    for i in xrange(N):\n",
    "        if trues[i] != preds[i]:\n",
    "            rmil += diffs[i] / (np.abs(trues[i]-preds[i]))\n",
    "    rmil = rmil / N\n",
    "    clc = np.exp(-rmil*(icp-0.95))\n",
    "    return icp, mil, rmil, clc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place id of interest\n",
    "ix = 7\n",
    "print ids[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true values we want to predict\n",
    "y_true = y_test[:,0,ix,0,0] * removed_std_all[ix][n_train:n_test] + removed_seasonality_all[ix][n_train:n_test]\n",
    "\n",
    "# naive baseline\n",
    "preds_naive = y[n_train-STEPS_AHEAD:n_test-STEPS_AHEAD,0,ix,0,0] * removed_std_all[ix][n_train:n_test] + removed_seasonality_all[ix][n_train:n_test]\n",
    "corr, mae_naive, mse, rae, rmse_naive, r2_naive = compute_error(y_true, preds_naive)\n",
    "print \"NAIVE: %.3f   %.3f   %.3f\" % (mae_naive,rmse_naive,r2_naive)\n",
    "\n",
    "# linear regression\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train[:,:,ix,0,0], y_train[:,0,ix,0,0])\n",
    "preds_lr = regr.predict(X_test[:,:,ix,0,0]) * removed_std_all[ix][n_train:n_test] + removed_seasonality_all[ix][n_train:n_test]\n",
    "\n",
    "corr, mae_lr, mse, rae, rmse_lr, r2_lr = compute_error(y_true, preds_lr)\n",
    "print \"LR:    %.3f   %.3f   %.3f\" % (mae_lr,rmse_lr,r2_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_outs=1):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(LSTM(layers[1], input_shape=(None, layers[0]), return_sequences=True))\n",
    "    model.add(ConvLSTM2D(filters=20, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 9, 1, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters=20, kernel_size=(3, 3),\n",
    "                       padding='same', return_sequences=False))\n",
    "    \n",
    "    #model.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "    #           activation='linear',\n",
    "    #           padding='same', data_format='channels_last'))\n",
    "\n",
    "    #model.add(LSTM(layers[2], return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print X_train[:,:,:,0,0].transpose([0,2,1]).shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model(num_outs=9)\n",
    "\n",
    "# checkpoint best model\n",
    "checkpoint = ModelCheckpoint(\"convlstm_mean.best.hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train[:,:,:,:,0].swapaxes(1,2),\n",
    "    batch_size=512,\n",
    "    epochs=120,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model.load_weights(\"convlstm_mean.best.hdf5\")\n",
    "\n",
    "preds_lstm = model.predict(X_test)\n",
    "print preds_lstm.shape\n",
    "preds_lstm = preds_lstm[:,ix,0,0] * removed_std_all[ix][n_train:n_test] + removed_seasonality_all[ix][n_train:n_test]\n",
    "print preds_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old results from above\n",
    "print \"NAIVE: %.3f   %.3f   %.3f\" % (mae_naive,rmse_naive,r2_naive)\n",
    "print \"LR:    %.3f   %.3f   %.3f\" % (mae_lr,rmse_lr,r2_lr)\n",
    "\n",
    "# results for LSTM\n",
    "corr, mae_lstm, mse, rae, rmse_lstm, r2_lstm = compute_error(y_true, preds_lstm)\n",
    "print \"LSTM:  %.3f   %.3f   %.3f\" % (mae_lstm,rmse_lstm,r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
